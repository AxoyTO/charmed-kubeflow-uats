{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b332dcf3-b5e7-4e42-9750-c5e40e5af9b8",
   "metadata": {},
   "source": [
    "# End-to-End UAT Test: Wine Quality Predictor\n",
    "\n",
    "This notebook demonstrates a complete end-to-end machine learning pipeline using Kubeflow, MLflow, and KServe. The pipeline covers the following steps:\n",
    "1. **Data Ingestion**: Downloading a wine quality dataset from a public URL.\n",
    "2. **Data Preprocessing**: Cleaning and transforming the dataset into a format suitable for model training.\n",
    "3. **Model Training**: Training an ElasticNet regression model to predict wine quality, with automatic logging of model artifacts to MLflow.\n",
    "4. **Model Deployment**: Deploying the trained model as a scalable inference service using KServe.\n",
    "5. **Model Inference**: Making predictions on new data using the deployed model and verifying the end-to-end functionality.\n",
    "6. **Cleanup**: Removing the deployed inference service after the test is completed to free up resources.\n",
    "\n",
    "This UAT test serves as a demonstration of the seamless integration of Kubeflow Pipelines with MLflow for model management and KServe for model deployment, along with proper resource management by cleaning up the deployed services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c8729-843c-45f1-80ad-da8eed206212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c9c41-a334-4aa6-b84b-ce1b66dcadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import mlflow\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from kfp.dsl import Input, Model, component\n",
    "from kfp.dsl import InputPath, OutputPath, pipeline, component\n",
    "from kserve import KServeClient\n",
    "from mlflow.tracking import MlflowClient\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ffa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP_PROXY = HTTPS_PROXY = NO_PROXY = None\n",
    "\n",
    "if os.environ.get(\"HTTP_PROXY\") and os.environ.get(\"HTTPS_PROXY\") and os.environ.get(\"NO_PROXY\"):\n",
    "    HTTP_PROXY = os.environ[\"HTTP_PROXY\"]\n",
    "    HTTPS_PROXY = os.environ[\"HTTPS_PROXY\"]\n",
    "    # add `.kubeflow` to NO_PROXY needed for pipelines\n",
    "    NO_PROXY = os.environ[\"NO_PROXY\"]\n",
    "\n",
    "\n",
    "def add_proxy(obj, http_proxy=HTTP_PROXY, https_proxy=HTTPS_PROXY, no_proxy=NO_PROXY):\n",
    "    \"\"\"Adds the proxy env vars to the PipelineTask object.\"\"\"\n",
    "    return (\n",
    "        obj.set_env_variable(name=\"http_proxy\", value=http_proxy)\n",
    "        .set_env_variable(name=\"https_proxy\", value=https_proxy)\n",
    "        .set_env_variable(name=\"HTTP_PROXY\", value=http_proxy)\n",
    "        .set_env_variable(name=\"HTTPS_PROXY\", value=https_proxy)\n",
    "        .set_env_variable(name=\"no_proxy\", value=no_proxy)\n",
    "        .set_env_variable(name=\"NO_PROXY\", value=no_proxy)\n",
    "    )\n",
    "\n",
    "\n",
    "def proxy_envs_set() -> bool:\n",
    "    if HTTP_PROXY and HTTPS_PROXY and NO_PROXY:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d166385-f03f-424a-81bd-9676e2a4b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constant for the Inference Service name\n",
    "ISVC_NAME = \"wine-regressor3\"\n",
    "MLFLOW_RUN_NAME = \"elastic_net_models\"\n",
    "MLFLOW_MODEL_NAME = \"wine-elasticnet\"\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.11\",  # Use Python 3.11 base image\n",
    "    packages_to_install=[\"requests==2.32.3\", \"pandas==2.2.2\"],\n",
    ")\n",
    "def download_dataset(url: str, dataset_path: OutputPath(\"Dataset\")) -> None:\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    # Download the dataset from the provided URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Convert the response content to a Pandas DataFrame\n",
    "    from io import StringIO\n",
    "\n",
    "    dataset = pd.read_csv(StringIO(response.text), header=0, sep=\";\")\n",
    "\n",
    "    # Save the DataFrame to a CSV file at the specified output path\n",
    "    dataset.to_csv(dataset_path, index=False)\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.11\",  # Use Python 3.11 base image\n",
    "    packages_to_install=[\"pandas==2.2.2\", \"pyarrow==15.0.2\"],\n",
    ")\n",
    "def preprocess_dataset(dataset: InputPath(\"Dataset\"), output_file: OutputPath(\"Dataset\")) -> None:\n",
    "    import pandas as pd\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset, header=0)\n",
    "\n",
    "    # Preprocess the DataFrame by standardizing column names\n",
    "    df.columns = [c.lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "    # Save the preprocessed DataFrame as a Parquet file\n",
    "    df.to_parquet(output_file)\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.11\",  # Use Python 3.11 base image\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.2.2\",\n",
    "        \"scikit-learn==1.5.1\",\n",
    "        \"mlflow==2.15.1\",\n",
    "        \"pyarrow==15.0.2\",\n",
    "        \"boto3==1.34.162\",\n",
    "    ],\n",
    ")\n",
    "def train_model(dataset: InputPath(\"Dataset\"), run_name: str, model_name: str) -> str:\n",
    "    import os\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Load the preprocessed dataset\n",
    "    df = pd.read_parquet(dataset)\n",
    "\n",
    "    # Define the target column for prediction\n",
    "    target_column = \"quality\"\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        df.drop(columns=[target_column]),\n",
    "        df[target_column],\n",
    "        test_size=0.25,\n",
    "        random_state=42,\n",
    "        stratify=df[target_column],\n",
    "    )\n",
    "\n",
    "    # Enable MLflow auto logging for scikit-learn models\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # Start an MLflow run and train the model\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        mlflow.set_tag(\"author\", \"kf-testing\")\n",
    "        lr = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "        mlflow.sklearn.log_model(lr, \"model\", registered_model_name=model_name)\n",
    "\n",
    "        # Return the model artifact URI as a string\n",
    "        model_uri = f\"{run.info.artifact_uri}/model\"\n",
    "        print(model_uri)\n",
    "        return model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdeb7a-2898-4a41-bba3-7f2b5c5b171e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256137a6-8a1c-4c4d-a544-9f716b1fbd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e2e04-394d-44d0-ace9-56e3435c86c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd6402-3edc-4582-a042-f2315d0cc9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29094980-dbdd-46ef-a793-37d7148db0a4",
   "metadata": {},
   "source": [
    "## Delete Inference Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffafef13-63fa-4a0a-868e-82c70e3c7118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35b016-6857-40e6-83b1-cf611a6d58ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b896d1d-0207-4cc8-a2e1-a2138be89ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d43d6a98-f051-4dca-9477-8ce455ab13fa",
   "metadata": {},
   "source": [
    "# Delete MLflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e15fe-3b44-46d1-89d6-622bc5cdc9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb49c25-7a45-43a8-9b61-592ead165255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
