{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b332dcf3-b5e7-4e42-9750-c5e40e5af9b8",
   "metadata": {},
   "source": [
    "# Notebook from Data Scientist with E2E scenario for Wine Quality Predictor\n",
    "\n",
    "This notebook demonstrates a complete end-to-end machine learning pipeline using Kubeflow, MLflow, and KServe. \n",
    "\n",
    "Expected Steps:\n",
    "1. **Data Ingestion**: Downloading a wine quality dataset from a public URL.\n",
    "2. **Data Preprocessing**: Cleaning and transforming the dataset into a format suitable for model training.\n",
    "3. **Model Training**: Training an ElasticNet regression model to predict wine quality, with automatic logging of model artifacts to MLflow.\n",
    "4. **Model Deployment**: Deploying the trained model as a scalable inference service using KServe.\n",
    "5. **Model Inference**: Making predictions on new data using the deployed model and verifying the end-to-end functionality.\n",
    "6. **Cleanup**: Removing the deployed inference service after the test is completed to free up resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c8729-843c-45f1-80ad-da8eed206212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c9c41-a334-4aa6-b84b-ce1b66dcadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import mlflow\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from kfp.dsl import Input, Model, component\n",
    "from kfp.dsl import InputPath, OutputPath, pipeline, component\n",
    "from kserve import KServeClient\n",
    "from mlflow.tracking import MlflowClient\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d166385-f03f-424a-81bd-9676e2a4b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "url = \"https://raw.githubusercontent.com/canonical/kubeflow-examples/main/e2e-wine-kfp-mlflow/winequality-red.csv\"\n",
    "\n",
    "# Here we define a constant for the Inference Service name\n",
    "ISVC_NAME = \"wine-regressor3\"\n",
    "MLFLOW_RUN_NAME = \"elastic_net_models\"\n",
    "MLFLOW_MODEL_NAME = \"wine-elasticnet\"\n",
    "\n",
    "\n",
    "# TODO: Define the function as a pipeline component. \n",
    "# Let base_image be Python 3.11 and figure out the packages to install\n",
    "@component()\n",
    "def download_dataset(url: str, dataset_path: OutputPath(\"Dataset\")) -> None:\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    # Download the dataset from the provided URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Convert the response content to a Pandas DataFrame\n",
    "    from io import StringIO\n",
    "\n",
    "    dataset = pd.read_csv(StringIO(response.text), header=0, sep=\";\")\n",
    "\n",
    "    # Save the DataFrame to a CSV file at the specified output path\n",
    "    dataset.to_csv(dataset_path, index=False)\n",
    "\n",
    "\n",
    "# TODO: Define the function as a pipeline component. \n",
    "# Let base_image be Python 3.11 and set the packages to install to pandas==2.2.2 and pyarrow==15.0.2\n",
    "@component()\n",
    "def preprocess_dataset(dataset: InputPath(\"Dataset\"), output_file: OutputPath(\"Dataset\")) -> None:\n",
    "    import pandas as pd\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(dataset, header=0)\n",
    "\n",
    "    # Preprocess the DataFrame by standardizing column names\n",
    "    df.columns = [c.lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "    # Save the preprocessed DataFrame as a Parquet file\n",
    "    df.to_parquet(output_file)\n",
    "\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.11\",  # Use Python 3.11 base image\n",
    "    packages_to_install=[\n",
    "        \"pandas==2.2.2\",\n",
    "        \"scikit-learn==1.5.1\",\n",
    "        \"mlflow==2.15.1\",\n",
    "        \"pyarrow==15.0.2\",\n",
    "        \"boto3==1.34.162\",\n",
    "    ],\n",
    ")\n",
    "def train_model(dataset: InputPath(\"Dataset\"), run_name: str, model_name: str) -> str:\n",
    "    import os\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Load the preprocessed dataset\n",
    "    df = pd.read_parquet(dataset)\n",
    "\n",
    "    # Define the target column for prediction\n",
    "    target_column = \"quality\"\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        df.drop(columns=[target_column]),\n",
    "        df[target_column],\n",
    "        test_size=0.25,\n",
    "        random_state=42,\n",
    "        stratify=df[target_column],\n",
    "    )\n",
    "\n",
    "    # TODO: Enable MLflow auto logging for scikit-learn models\n",
    "\n",
    "\n",
    "    # Start an MLflow run and train the model\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        mlflow.set_tag(\"author\", \"kf-testing\")\n",
    "        lr = ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        #TODO: Log the Linear Regression model and register it with model_name\n",
    "        mlflow.sklearn.log_model(lr, \"model\", registered_model_name=model_name)\n",
    "\n",
    "        # Return the model artifact URI as a string\n",
    "        model_uri = f\"{run.info.artifact_uri}/model\"\n",
    "        print(model_uri)\n",
    "        return model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cf50a6",
   "metadata": {},
   "source": [
    "**TODO:** Write a pipeline component to deploy the model with KServe. The function should return the ISVC URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdeb7a-2898-4a41-bba3-7f2b5c5b171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.11\",  # Use Python 3.11 base image\n",
    "    packages_to_install=[\"kserve==0.13.1\", \"kubernetes==26.1.0\", \"tenacity==9.0.0\"],\n",
    ")\n",
    "def deploy_model_with_kserve(model_uri: str, isvc_name: str) -> str:\n",
    "    from kubernetes.client import V1ObjectMeta\n",
    "    from kserve import (\n",
    "        constants,\n",
    "        KServeClient,\n",
    "        V1beta1InferenceService,\n",
    "        V1beta1InferenceServiceSpec,\n",
    "        V1beta1PredictorSpec,\n",
    "        V1beta1SKLearnSpec,\n",
    "    )\n",
    "    from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "    #\n",
    "    # 1. Initialize the Inference Service specification\n",
    "    # 2. Deploy the Inference Service using KServe\n",
    "    # 3. Implement a logic to make sure the Inference Service is ready\n",
    "    # 4. Wait until the service is ready and get the service URL. \n",
    "    # 5. Return it\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e653f90",
   "metadata": {},
   "source": [
    "**TODO:** Create the pipeline itself using the components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256137a6-8a1c-4c4d-a544-9f716b1fbd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch environment variables for MLflow tracking and AWS credentials\n",
    "# These are guaranteed to be present because of the mlflow's poddefault please refer to [this guide](https://documentation.ubuntu.com/charmed-mlflow/en/latest/tutorial/mlflow-kubeflow/\n",
    "\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "mlflow_s3_endpoint_url = os.getenv(\"MLFLOW_S3_ENDPOINT_URL\")\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "\n",
    "@pipeline(name=\"download-preprocess-train-deploy-pipeline\")\n",
    "def download_preprocess_train_deploy_pipeline(url: str):\n",
    "    # Step 1: Download the dataset from the URL\n",
    "    # Step 2: Preprocess the downloaded dataset\n",
    "    # Step 3: Train the model on the preprocessed dataset\n",
    "    # Step 4: Deploy the trained model with KServe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b280509",
   "metadata": {},
   "source": [
    "**TODO:** Initialize a KFP Client and compile the pipeline. Then run it. Variable for the run should be \"run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e2e04-394d-44d0-ace9-56e3435c86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize a KFP client\n",
    "# This client is used to interact with the Kubeflow Pipelines API.\n",
    "client = None\n",
    "\n",
    "# This URL points to the dataset that will be downloaded and processed in the pipeline.\n",
    "url = \"https://raw.githubusercontent.com/canonical/kubeflow-examples/main/e2e-wine-kfp-mlflow/winequality-red.csv\"\n",
    "\n",
    "# 2. Compile the pipeline\n",
    "\n",
    "# 3. Run the pipeline, set enable_caching to False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197b630",
   "metadata": {},
   "source": [
    "**TODO:** Initialize the KServe client, and try the inference service on the defined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the KServe client\n",
    "# This client is used to interact with the KServe Inference Service.\n",
    "kserve_client = None\n",
    "\n",
    "# 2. Retrieve the Inference Service details\n",
    "# Fetches the Inference Service by name and extracts the URL for making predictions.\n",
    "# YOUR CODE HERE\n",
    "print(\"Inference URL:\", inference_service_url)\n",
    "\n",
    "# This data matches the expected input format of the deployed model, with each instance being a list of feature values.\n",
    "input_data = {\n",
    "    \"instances\": [\n",
    "        [7.4, 0.7, 0.0, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4],\n",
    "        [7.8, 0.88, 0.0, 2.6, 0.098, 25.0, 67.0, 0.9968, 3.2, 0.68, 9.8],\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 3. Send a prediction request to the Inference Service\n",
    "# This sends the input data to the model for prediction via a POST request and prints the response.\n",
    "# YOUR CODE HERE\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29094980-dbdd-46ef-a793-37d7148db0a4",
   "metadata": {},
   "source": [
    "## Delete Inference Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b896d1d-0207-4cc8-a2e1-a2138be89ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d6a98-f051-4dca-9477-8ce455ab13fa",
   "metadata": {},
   "source": [
    "# Delete MLflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e15fe-3b44-46d1-89d6-622bc5cdc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
